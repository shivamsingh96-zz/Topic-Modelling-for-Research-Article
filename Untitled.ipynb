{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SHIVAM\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\SHIVAM\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\SHIVAM\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK modules\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec # Word2Vec module\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, remove_stopwords, strip_numeric, stem_text\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "submission_data = pd.read_csv(\"sample_submission_UVKGLZE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                      0\n",
      "TITLE                   0\n",
      "ABSTRACT                0\n",
      "Computer Science        0\n",
      "Physics                 0\n",
      "Mathematics             0\n",
      "Statistics              0\n",
      "Quantitative Biology    0\n",
      "Quantitative Finance    0\n",
      "dtype: int64\n",
      "Index(['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics',\n",
      "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting binary column to category\n",
    "to_convert = ['Computer Science', 'Physics', 'Mathematics','Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
    "\n",
    "# Make a copy of train data\n",
    "topic_data = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the binary fields to categorical fields\n",
    "topic_data = topic_data[topic_data[to_convert]==1].stack().reset_index().drop(0,1)\n",
    "\n",
    "topic_data['ID'] = topic_data['level_0'].apply(lambda x: x+1)\n",
    "topic_data = topic_data.drop('level_0', axis=1)\n",
    "\n",
    "# Merge the data based on ID\n",
    "merge_data = train_data.merge(topic_data, how='left', on='ID' )\n",
    "# Drop all the binary fields\n",
    "merge_data = merge_data.drop(to_convert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26262</td>\n",
       "      <td>20970</td>\n",
       "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
       "      <td>We present a new approach for identifying si...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26263</td>\n",
       "      <td>20971</td>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26264</td>\n",
       "      <td>20971</td>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26265</td>\n",
       "      <td>20972</td>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26266</td>\n",
       "      <td>20972</td>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26267 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TITLE  \\\n",
       "0          1        Reconstructing Subject-Specific Effect Maps   \n",
       "1          2                 Rotation Invariance Neural Network   \n",
       "2          3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3          4  A finite element approximation for the stochas...   \n",
       "4          5  Comparative study of Discrete Wavelet Transfor...   \n",
       "...      ...                                                ...   \n",
       "26262  20970  Analysing Soccer Games with Clustering and Con...   \n",
       "26263  20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "26264  20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "26265  20972   Why optional stopping is a problem for Bayesians   \n",
       "26266  20972   Why optional stopping is a problem for Bayesians   \n",
       "\n",
       "                                                ABSTRACT          CATEGORY  \n",
       "0        Predictive models allow subject-specific inf...  Computer Science  \n",
       "1        Rotation invariance and translation invarian...  Computer Science  \n",
       "2        We introduce and develop the notion of spher...       Mathematics  \n",
       "3        The stochastic Landau--Lifshitz--Gilbert (LL...       Mathematics  \n",
       "4        Fourier-transform infra-red (FTIR) spectra o...  Computer Science  \n",
       "...                                                  ...               ...  \n",
       "26262    We present a new approach for identifying si...  Computer Science  \n",
       "26263    The sum of Log-normal variates is encountere...       Mathematics  \n",
       "26264    The sum of Log-normal variates is encountere...        Statistics  \n",
       "26265    Recently, optional stopping has been a subje...       Mathematics  \n",
       "26266    Recently, optional stopping has been a subje...        Statistics  \n",
       "\n",
       "[26267 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the column to Category\n",
    "merge_data = merge_data.rename({'level_1':'CATEGORY'}, axis=1)\n",
    "merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer Science' 'Mathematics' 'Physics' 'Quantitative Biology'\n",
      " 'Quantitative Finance' 'Statistics']\n"
     ]
    }
   ],
   "source": [
    "articles = merge_data\n",
    "\n",
    "# list unique classes\n",
    "print(np.unique(articles.CATEGORY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAFzCAYAAAC+bzSQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debhcVZnv8e9LwigyR1SgDWLUxgkl4oSKYAtoK6BhUBG0vY16cUJtx26hUfqKaKPi1EwySAvIIIPYgoy2KJhgIASMRFCJogRBFBE08N4/1ipSOTlDJTl1Kiv5fp7nPKf22tOqVXvv+tUeIzORJElSO9YYdAUkSZK0bAxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY2ZPOgK9MNmm22WU6dOHXQ1JEmSxjRr1qy7MnPKsoyzSga4qVOnMnPmzEFXQ5IkaUwR8ctlHcdDqJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY2ZPOgKDNL2/3LKoKvQhFlHHTDoKkiSpC7ugZMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqTF8DXEQcEhFzI+LGiPhGRKwTEVtHxDURcUtEnBERa9Vh167d82v/qV3T+UgtnxcRu/azzpIkSSu7vgW4iNgCeDcwPTOfDkwC9gOOBI7OzGnAPcBb6yhvBe7JzCcBR9fhiIht63hPA3YDvhwRk/pVb0mSpJVdvw+hTgbWjYjJwHrAHcDOwFm1/8nAnvX1HrWb2n+XiIhafnpmPpiZtwHzgR36XG9JkqSVVt8CXGb+GvgM8CtKcLsXmAX8ITMX1cEWAFvU11sAt9dxF9XhN+0uH2YcSZKk1U4/D6FuTNl7tjXweOBRwO7DDJqdUUboN1L50PkdFBEzI2LmwoULl6/SkiRJDejnIdSXA7dl5sLM/BtwDvBCYKN6SBVgS+A39fUCYCuA2n9D4O7u8mHGeURmHpuZ0zNz+pQpU/rxfiRJklYK/QxwvwKeHxHr1XPZdgFuAi4HZtRhDgTOq6/Pr93U/pdlZtby/epVqlsD04Br+1hvSZKkldrksQdZPpl5TUScBVwHLAJ+AhwLfBs4PSI+WctOqKOcAJwaEfMpe972q9OZGxFnUsLfIuDgzHyoX/WWJEla2fUtwAFk5qHAoUOKb2WYq0gz8wFg7xGmcwRwxLhXUJIkqUE+iUGSJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIa09cAFxEbRcRZEfHTiLg5Il4QEZtExCURcUv9v3EdNiLiCxExPyJuiIjndE3nwDr8LRFxYD/rLEmStLLr9x64zwP/k5lPBZ4F3Ax8GLg0M6cBl9ZugN2BafXvIOArABGxCXAo8DxgB+DQTuiTJElaHfUtwEXEBsBLgBMAMvOvmfkHYA/g5DrYycCe9fUewClZ/AjYKCIeB+wKXJKZd2fmPcAlwG79qrckSdLKbnIfp/1EYCHwtYh4FjALeA+weWbeAZCZd0TEY+rwWwC3d42/oJaNVC5JK6UrX/LSQVehCS+96spBV0FqVj8PoU4GngN8JTOfDfyZxYdLhxPDlOUo5UuOHHFQRMyMiJkLFy5cnvpKkiQ1oZ8BbgGwIDOvqd1nUQLd7+qhUer/O7uG36pr/C2B34xSvoTMPDYzp2fm9ClTpozrG5EkSVqZ9C3AZeZvgdsj4im1aBfgJuB8oHMl6YHAefX1+cAB9WrU5wP31kOt3wVeEREb14sXXlHLJEmSVkv9PAcO4F3AaRGxFnAr8BZKaDwzIt4K/ArYuw57EfBKYD5wfx2WzLw7Ij4B/LgOd3hm3t3nekuSJK20+hrgMnM2MH2YXrsMM2wCB48wnROBE8e3dpIkSW3ySQySJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY3p96O0pCX86vBnDLoKTfi7j88ZdBUkSSsx98BJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUmMmDroCk/nrRMS8adBWa8IN3/WDQVZCknrkHTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTGGOAkSZIaY4CTJElqjAFOkiSpMQY4SZKkxhjgJEmSGmOAkyRJakxPAS4iLu2lTJIkSf03ebSeEbEOsB6wWURsDETttQHw+D7XTZIkScMYNcABbwPeSwlrs1gc4P4IfKmP9ZIkSdIIRg1wmfl54PMR8a7MPGaC6iRJkqRRjLUHDoDMPCYiXghM7R4nM0/pU70kSZI0gp4CXEScCmwDzAYeqsUJGOAkSZImWE8BDpgObJuZ2c/KSJIkaWy93gfuRuCx/ayIJEmSetPrHrjNgJsi4lrgwU5hZr6mL7WSJEnSiHoNcIf1sxKSJEnqXa9XoV7Z74pIkiSpN71ehfonylWnAGsBawJ/zswN+lUxSZIkDa/XPXCP7u6OiD2BHfpSI0mSJI2q16tQl5CZ3wJ2Hue6SJIkqQe9HkJ9bVfnGpT7wnlPOEmSpAHo9SrUV3e9XgT8Athj3GsjSZKkMfV6Dtxb+l0RSZIk9aanc+AiYsuIODci7oyI30XE2RGxZb8rJ0mSpKX1ehHD14DzgccDWwAX1DJJkiRNsF4D3JTM/FpmLqp/JwFT+lgvSZIkjaDXAHdXROwfEZPq3/7A7/tZMUmSJA2v1wD3T8A+wG+BO4AZgBc2SJIkDUCvtxH5BHBgZt4DEBGbAJ+hBDtJkiRNoF73wD2zE94AMvNu4Nn9qZIkSZJG02uAWyMiNu501D1wve69kyRJ0jjqNYR9Frg6Is6iPEJrH+CIvtVKkiRJI+r1SQynRMRMygPsA3htZt7U15pJkiRpWL0eQiUzb8rML2bmMcsS3uptR34SERfW7q0j4pqIuCUizoiItWr52rV7fu0/tWsaH6nl8yJi197fniRJ0qqn5wC3At4D3NzVfSRwdGZOA+4B3lrL3wrck5lPAo6uwxER2wL7AU8DdgO+HBGTJqDekiRJK6W+Brj6vNRXAcfX7qAchj2rDnIysGd9vUftpvbfpQ6/B3B6Zj6YmbcB84Ed+llvSZKklVm/98B9Dvgg8HDt3hT4Q2Yuqt0LKM9Wpf6/HaD2v7cO/0j5MOM8IiIOioiZETFz4cKF4/0+JEmSVhp9C3AR8Y/AnZk5q7t4mEFzjH6jjbO4IPPYzJyemdOnTPExrZIkadXVz3u5vQh4TUS8ElgH2ICyR26jiJhc97JtCfymDr8A2ApYEBGTgQ2Bu7vKO7rHkSRJWu30bQ9cZn4kM7fMzKmUixAuy8w3ApdTnqUKcCBwXn19fu2m9r8sM7OW71evUt0amAZc2696S5IkrewG8TSFDwGnR8QngZ8AJ9TyE4BTI2I+Zc/bfgCZOTcizgRuAhYBB2fmQxNfbUmSpJXDhAS4zLwCuKK+vpVhriLNzAeAvUcY/wh88oMkSRIwMfeBkyRJ0jgywEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktSYvgW4iNgqIi6PiJsjYm5EvKeWbxIRl0TELfX/xrU8IuILETE/Im6IiOd0TevAOvwtEXFgv+osSZLUgn7ugVsEvD8z/x54PnBwRGwLfBi4NDOnAZfWboDdgWn17yDgK1ACH3Ao8DxgB+DQTuiTJElaHfUtwGXmHZl5XX39J+BmYAtgD+DkOtjJwJ719R7AKVn8CNgoIh4H7Apckpl3Z+Y9wCXAbv2qtyRJ0spuQs6Bi4ipwLOBa4DNM/MOKCEPeEwdbAvg9q7RFtSykcolSZJWS30PcBGxPnA28N7M/ONogw5TlqOUD53PQRExMyJmLly4cPkqK0mS1IC+BriIWJMS3k7LzHNq8e/qoVHq/ztr+QJgq67RtwR+M0r5EjLz2MycnpnTp0yZMr5vRJIkaSXSz6tQAzgBuDkz/7Or1/lA50rSA4HzusoPqFejPh+4tx5i/S7wiojYuF688IpaJkmStFqa3Mdpvwh4EzAnImbXso8CnwLOjIi3Ar8C9q79LgJeCcwH7gfeApCZd0fEJ4Af1+EOz8y7+1hvSZKklVrfAlxm/i/Dn78GsMswwydw8AjTOhE4cfxqJ0mS1C6fxCBJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjDHCSJEmNMcBJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMmD7oCkiStqC++/4JBV6EJ7/zsqwddBY0T98BJkiQ1xgAnSZLUGAOcJElSYwxwkiRJjTHASZIkNcYAJ0mS1BgDnCRJUmMMcJIkSY0xwEmSJDXGACdJktQYA5wkSVJjfBaqJElaZkfsP2PQVWjCx75+Vl+m6x44SZKkxhjgJEmSGmOAkyRJaowBTpIkqTHNBLiI2C0i5kXE/Ij48KDrI0mSNChNBLiImAR8Cdgd2BZ4fURsO9haSZIkDUYTAQ7YAZifmbdm5l+B04E9BlwnSZKkgWglwG0B3N7VvaCWSZIkrXYiMwddhzFFxN7Arpn5f2r3m4AdMvNdXcMcBBxUO58CzJvwio6PzYC7Bl2J1YxtPvFs84lnm08823zitdrmT8jMKcsyQitPYlgAbNXVvSXwm+4BMvNY4NiJrFQ/RMTMzJw+6HqsTmzziWebTzzbfOLZ5hNvdWrzVg6h/hiYFhFbR8RawH7A+QOukyRJ0kA0sQcuMxdFxDuB7wKTgBMzc+6AqyVJkjQQTQQ4gMy8CLho0PWYAM0fBm6QbT7xbPOJZ5tPPNt84q02bd7ERQySJElarJVz4CRJklSt0gEuIh4bEadHxM8j4qaIuCginjygunx0HKbx/Ii4JiJmR8TNEXHYGMNfFBEbreh8J0JEZESc2tU9OSIWRsSFY4y3XUS8sqv7sIj4QD/rOmT+UyPiDV3d0yPiCxM1/4kQER+LiLkRcUNd9p4XEe+NiPV6GHeJ4cZaJpd1+NVBRDxU2/3GiPhmRKxXl7sbx2Hab4+IA8ajnuMpIraMiPMi4paIuDUivhgRa/dhPjtFxAu7uh9pj4h4c0Q8vodpLDFcRBw/Hk8Kiogr6uMjO9v7g7r6jbleRMR9yzAv23vJ9p4dETNq+dUrOu2+ycxV8g8I4IfA27vKtgNePKD63Lcc40wa0j0PeFanH7DtoNt5PNsH+Amwbu3eHZgNXDjGeG8GvtjVfRjwgQms905j1bHlP+AFdT1au3ZvBjwe+AWwWQ/j9zTc8g6/Ovx1bzuA04D3AVOBGwddtz693wCuBd5SuycBJwCf78O8RtxeAFcA03uYRk/DLUfdHpkusAlwD7DW8iw3tveytXcrfwOvQN/eGOwMXDVCvwCOAm4E5gD71vKdgCuBM4GfAZ8C3lgX7jnANnW4k4CvAt+vw/1jLR8aJi6s0/wU8BAlkJxW++1fpzsb+C9qWKMEmcOBa4Adh9T7HuAxw7yf9YGv1TreALyulj/yZTjG/I4Argd+BGxeyzcHzq3l1wMvHG064/B53Qf8BzCjdp8CfIgajiiPU7uaEvKuptyseS3gV8DCWp996wbixLoy3gq8u2seo7XBkcAs4Ht1Xp3xX1OHmVo/7+vqX6c9fgTcW6d5CF2BbrjPhbJxPInFy94hg15XxvhcXgtcMKTs3cBfa/0vr2VfAWYCc4F/H2W4X1BC4KOAb9dl68b62Y04fH19QG3H64FTa9nedfzrGWF9b/2PJQPc24Ev1+XxZuC42uYXA+sC2wDXdQ0/DZhVX38KuKm24Wdq2WHUL1TgSXX5v74u49sAjwOuqsv3jUzAD2Bgl6GfJbABZfu3PiNsZ0daDruWo3+v72sO8NTahr8Ffl3f34s77QHMoGwX5tV+6wIfp9zS6kbKifIxwnBXANOBdwCf7qrDm4Fj6usxt6MsGeD+jnI/1Eld76ezXryv1ulG4L1DlxtG/r5boy5LvwB+T7lIcEZt/wu62vso4OerU3sPt/5Rtu1XAGcBP6X8mOpcR7BUXbumeWSd98+o6w/le+AzLP5ueFct356SQWZR7rrxuFHXlUFvnPq4EXg3cPQI/V4HXFIbcXNKCHhc/YD+UF+vXRe0zpfRe4DP1dcnAf9DWQGmUVasdRh9w9K9Ef57ygqyZu3+MnBAfZ3APiPU++OUlepc4G3AOrX8yE7davfG3St5D/N7dX39aeBf6+szqBuD2k4bjjadcfi87gOeWVeOdSgr2k4sDkMbAJPr65cDZ3etpEP3wF1dP7/NKBumNXtog93r63MpX4ZrAs8CZtfy9braexows2ulvrBr/t11Xupzoaygl3SVbTTodWWMz2X9+ln8rLbZS7uXra7hNulaVq4AnjnCcJ1l8nXAcV3lG44x/NMoG+3NhsxvDrBFC225IutG/T8ZOI/yRTUVWARsV/udCexfX1/eVf4fwLsoe3DmsfiLZaOu9aUT4K4B9qqv16nL/PuBj3V9to+egPc77Lab8uNtO0bfzo62HHa+JP8vcPzQ9z9Me1xB1xd6Z9r19aks3m4OHe4KSqCYQnmGd6f8O8CO9LgdrdOZR/mC/wvwtmHWi+3rOvAoyro6F3j2kOVmpO+7GZTQ9h5KqLmnlgUloMyp7f1DltzGrertPbv+bTqkHXei/FjfkvLd/0PqTpYx6vrZ+vqVwPfq63cAZ7P4O20TynfO1cCUWrYv5ZZpI64rq/Q5cKPYEfhGZj6Umb+jJN7n1n4/zsw7MvNB4OeUL3MoC/PUrmmcmZkPZ+YtlD01T12G+e9CWfF+HBGza/cTa7+HKB/sUjLzcMqCejHwBkqIhBJovtQ13D3LML+/UlZIKKm/8x53pvy6orbTvWNMZ4Vl5g11/q9n6VvGbAh8s573czTlC30k387MBzPzLuBOykZrrDbotOUc4MrM/BtLfuZrAsdFxBzgm0Av51wM97ncCjwxIo6JiN2AP/YwnYHJzPso7XYQZU/nGRHx5mEG3ScirqN8yT6NsdtnDvDyiDgyIl5cl6/R7AycVT9TMvPuWv4D4KSI+GfKl8iqaN26zM6kfPmeUMtvy8zZ9XX3uns88JaImET5EvhvynL2AHB8RLwWuL97BhHxaEoQPhcgMx/IzPspexXeUs+3fUZm/qk/b3EJQflRNVz5WEZbDs+p/7vbalm8rJ6DPIeyPI62DSIzFwK31nOXN6UcNfgBy7YdfWNmPpOyB+4DEfGEIf13BM7NzD/XdfUcyp6tocMM9323I2VbBvBnSvAnS3o4lRIqHk3ZM/vLEeq3Krb3dvXv98P0vzYzF2Tmw5SQ13lfo9V1uHZ4OfDVzFxU6353re/TgUtqPf+VEhZH1Mx94JbDXMqvieGMtiF4sOv1w13dD7Nkew3dwCTlF3F3KF5nlPmfnJkfGabfA5n50EiVy8yfA1+JiOOAhXVBHWmD18v8/lZXWCjhcbRlYrTpjJfzKbuWdwI27Sr/BOWw2l4RMZXyy2Yk3Z9h5z312gaPfOaZ+XBEdNrjEOB3lL1ya1C+DMey1OeSmfdExLOAXYGDgX2Af+phWgNTl8crgCvqBurA7v4RsTXlMMhz6/s7iZGX/c40fxYR21N+lf6/iLi4/kAZybDLeGa+PSKeB7wKmB0RI214W/aXzNyuuyAiYOnlfN36+mzgUOAyyuHT39dxdqB8ee0HvJPyRfPIJIebcWZeFREvobTvqRFxVGaessLvaHRzKXuNFlcuYgPKD7F5lC+5pbazPSyHnfYaazu3lIhYh7LnZnpm3l4D7ajLeHUGZR3/KSVoZZQPb5m2o5m5sAal57FkmOol1I40TKe8097dzw/9JmXv2LMpe2a7p7HKt/colvpu6aGuw7XDcNuzAOZm5gt6rcyqvAfuMmDt+sscgIh4bkS8lHJOx74RMSkipgAvoRyjXhZ7R8QaEbENJc3Po+w23q6Wb0U5l6rjbxGxZn19KTAjIh5T67XJML+slhIRr6oLI5TDeA9RDvleTNkgd4bbeMioyzO/Sym7eanttMHy1nsZnQgcnplzhpRvSDmkDeUQSsefKL8Sx7Kidd8QuKP+8noTi/f2jDb/pT6XiNgMWCMzzwb+DXjOMtRhwkXEUyJiWlfRdpQvkO73vQHlF/y9EbE55QKUjmHbp15Fdn9mfp0S2J8z2vCUz2+f+oOFiNik/t8mM6/JzI9TvoC2Gmbc1UpmPkA5f+YrlHMwiYj1KYepLwLeS/kcu8f5I7AgIvasw68d5WrXJwB3ZuZxlD1/E7G8Xgqs13V14iTgs5TDpn9h5O3saMvhSEZbf7v7db6Q76ptOWOE4YY6B9iTclThjK73t0zboihXZj+bclSo21XAnvWzehSwF+Vc3aHDDPd997+U4HYZpe1eUec1CfgXYD7lPOTTWc3aexmNVteRXAy8vbODoG7P5gFTIuIFtWzNiBh1r+MqG+DqHpW9gH+IchuRuZRfFL+hnOfUORn6MuCDmfnbZZzFPMqu6O9QrnR9gLK79jbK4aHPUE7g7DgWuCEiTsvMmyi7Ry+OiBso5yc8rod5vgmYV3evnkrZ3fsQ8Elg4yi3GbgeeNmQtlie+b2Hslt4DmXX79NWoN49q7unPz9Mr09T9tT8gCUPlV0ObBvlsu99R5nuitb9y8CBEfEj4MmUDReU5WhRRFwfEYcMGWe4z2ULyp6s2ZRzKfu5N3M8rA+cHOU2PDdQDpEcRlmevxMRl2fm9ZRDKHMpAfwHXeM/MtyQ6T4DuLa2w8cobTXi8FkenXcEcGVty/+svY6KiDlRDq1fRVmnVU6wThafAvJo4ML6GV5J2aM81JuAd9dhrgYeS9kTPjsifkL5sh9u3RxXXdvuGRFxC+U81ocz84g6yLDb2TGWw5FcAOxVtx9DDz2eBHy1LqMPUi4YmQN8i3JoeanhImLd7gnU0yZuAp6QmdfWsmXZFp1W5z8LOCkzZw2Z/nV1/tdS9pQdn5k/GTKNkb7vzqacv30j5ejCn4HPUdubchHC7ZRlaXVp72WWmX8Ypa4jOZ5yOsQNdXv2hsz8KyX8HVnLZgMvHGUaPolhedRdxRdm5lmDroskDRXlXogbZua/DbouKyrKfcO+Abx2aIDRiomI9TPzvrpn+1rgRZQjSt+gXGF/cWaeMNo0NDir8jlwkrTaiYhzKbcA2XmsYVuQmVcD432qhooLo9wQeC3gE3XP3G8j4i7KXqqvD7R2GpV74CRJkhqzyp4DJ0mStKoywEmSJDXGACdJktQYA5ykVUJEPDYiTq+3DbopIi6KiCfXfodExAMRsWHt3rXehmB2RNwXEfPq61MiYqeIuLer/+yIeHkdb/OI+O+IuDUiZkXEDyNir6467BgR10bET+vfQV39DouIX9fp3RQRr6/lB0XEGV3DbVDfw9YT1XaS2mOAk9S8iAjK/a6uyMxtMnNb4KOUu/dDubHnjyn3FyMzv9t5ZA7lEVWdR+gcUIf/ftcjdbbLzO/VeXyL8qD1J2bm9pSnGmxZ6/BYymOr3p6ZT6U8quhtEfGqrqoeXee5B/BfUW7ufRywZSckAodTnoF427g3lKRVhgFO0qrgZZRHon21U5CZszPz+1GelrI+5Waer1+BeewM/HXIPH6ZmcfUzoMpN1vt3Oj0LuCDwIeHTijLM5TvBzauN/ysNK0AAAG1SURBVK59B/C5iJhOedzVUStQT0mrAe8DJ2lV8HTK3eqH83rKjUm/DzwlIh6TmXeOMb0X1zvCd7yO8oDq60YYntr/5CFlMxnmIdwR8Rzglk49MvOGiPgu5bE/e9a7skvSiNwDJ2lVtx9wen2O7TnA3j2MM/QQ6tBnUBIRX6qPUOs8Ome4B1QzpOyQiJhHeezRYUOG+xLw68wc+tgxSVqKAU7SqmAusP3Qwoh4JjANuCQifkEJc8t7GHUuXQ9zz8yDKYc7p3T1nz5knO0pz2bsODoznwLsC5wSEet09Xu4/knSmAxwklYFlwFrR8Q/dwoi4rmUh68flplT69/jgS0iYnkezXQZsE5EvKOrbL2u118C3hwR29X5bwocCXx66IQy8xzK4dUDl6MekmSAk9S+eiHAXsA/1FtwzKUcotyJcnVqt3Mpe+JG8+IhtxGZUeexJ/DSiLgtIq6lnPP2oVqHO4D9geMi4qfA1ZSrSS8YYR6HA++LCLfDkpaZz0KVJElqjL/8JEmSGmOAkyRJaowBTpIkqTEGOEmSpMYY4CRJkhpjgJMkSWqMAU6SJKkxBjhJkqTG/H+wOAhp/E8CvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot category data\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(articles.CATEGORY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer object\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.filters = [strip_tags,\n",
    "                       strip_numeric,\n",
    "                       strip_punctuation,\n",
    "                       lambda x: x.lower(),\n",
    "                       lambda x: re.sub(r'\\s+\\w{1}\\s+', '', x),\n",
    "                       remove_stopwords]\n",
    "    def __call__(self, doc):\n",
    "        clean_words = self.__apply_filter(doc)\n",
    "        return clean_words\n",
    "    \n",
    "    def __apply_filter(self, doc):\n",
    "        try:\n",
    "            cleanse_words = set(preprocess_string(doc, self.filters))\n",
    "#             filtered_words = set(wnl.lemmatize(w) if w.endswith('e') or w.endswith('y') else porter.stem(w) for w in cleanse_words)\n",
    "            return ' '.join(cleanse_words)\n",
    "        except TypeError as te:\n",
    "            raise(TypeError(\"Not a valid data {}\".format(te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the Title and Abstract data\n",
    "articles['TEXT'] = articles['TITLE'].map(str) + articles['ABSTRACT'].map(str)\n",
    "\n",
    "articles['Processed'] = articles['TEXT'].apply(DataPreprocess())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ad specific dispersed bootstrap noisy particular predictive demonstrate dataset imaging results improve alterations identifiying detections classifiers maps article cerebrospinal reduce associated database usingfinite subject mini proposed yield noise detection sample state train method form directly beta isolated existing rarely reconstruction extracted neuroimaging composed aims improvement condition inclassifier markers averaging sampling synthetically asmaximumposteriori yields reconstructing indiagnostic thickness performed fluid iswrapper measurement global different individual longitudinal fashion parameters estimated evaluation correlation locale adni alzheimerdisease mental inference type analyzing compared examination allow presence related binary amyloid problem higher islands levels score givensubjectdata approaches non widely error specifically generated data posed subjectdata model initiative training accuracy models named rsm examples disease synthetic globale cortical detecting experimental effect modeling analyses proposereconstruction studies algorithm mannere withprior local reliability information',\n",
       "       'insymbol overlap target thesymbol network convolutional orientation named architecture achieve bringnew position cases paper great image recognition cyclic rotation invariance cnn translation values learning multiple purpose detection non layer tasks shot neural',\n",
       "       'balls generalisation particular kernel introduce functions union terms harmonics gegenbauer poisson representation cauchy polyharmonic polynomials arenatural ball notion construct harmonic polyharmonics holomorphic rotated connection classical theory zonal study kernels lie spherical allows develop analogously hua',\n",
       "       ...,\n",
       "       'copula normal finding assess shifting rvs results finally communication vanishing accurate values estimators regions encountered high proposed approximation yield asymptotically estimating small tail challenging left propose instead applications mean developed existing right matrix analysis result estimates evaluated variables variance literature sampling random efficient correlated simulation variates representsmajor financial probability present gaussian methods main considered wireless estimator importance compared performances problem techniques ensured reduction approaches primordial performance error assumption known variate sum consider accuracy approach technique engineering covariance withcontrol systems log precision estimation context work relative combining undermild',\n",
       "       'bayes specific methods recently argues recommends means types parameters bayesians optional applications et hypothesis slightly ranging rouder problematic community extending default type ii soon priors debate addresses stopping illustrate iii distinguish article practical practice issues bayesian psychology problem break severe circumstances beensubject factor specifies sense rouderexperiment varying having pragmatic isproblem use wagenmakers testing question resilience equipped al',\n",
       "       'bayes specific methods recently argues recommends means types parameters bayesians optional applications et hypothesis slightly ranging rouder problematic community extending default type ii soon priors debate addresses stopping illustrate iii distinguish article practical practice issues bayesian psychology problem break severe circumstances beensubject factor specifies sense rouderexperiment varying having pragmatic isproblem use wagenmakers testing question resilience equipped al'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['Processed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\shivam singh\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shivam singh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\shivam singh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\shivam singh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.16.5)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\shivam singh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shivam singh\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_to_object_array' from 'sklearn.utils' (C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-87dae650cd28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install imbalanced-learn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munder_sampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mover_sampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\combine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_docstring\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSubstitution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_neighbors_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_to_object_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_to_object_array' from 'sklearn.utils' (C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomOverSampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-11f7c8c2f680>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CATEGORY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minority'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomOverSampler' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.reshape(articles['Processed'].values, (-1,1))\n",
    "y = np.reshape(articles['CATEGORY'].values, (-1,1))\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=27)\n",
    "\n",
    "X_res, y_res = ros.fit_resample(X, y)\n",
    "\n",
    "print(X_res.shape, y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(articles['Processed'].values, (-1,1))\n",
    "y = np.reshape(articles['CATEGORY'].values, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vector, X_train, X_test):\n",
    "    vector_fit = vector.fit(X_train)\n",
    "    \n",
    "    X_train_vec = vector_fit.transform(X_train)\n",
    "    X_test_vec = vector_fit.transform(X_test)\n",
    "    \n",
    "    print(\"Vectorization is completed.\")\n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "def label_encoding(y_train):\n",
    "    \"\"\"\n",
    "        Encode the given list of class labels\n",
    "        :y_train_enc: returns list of encoded classes\n",
    "        :labels: actual class labels\n",
    "    \"\"\"\n",
    "    lbl_enc = LabelEncoder()\n",
    "    \n",
    "    y_train_enc = lbl_enc.fit_transform(y_train)\n",
    "    labels = lbl_enc.classes_\n",
    "    \n",
    "    return y_train_enc, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc_train, labels = label_encoding(y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_enc_train, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18386, 1) (7881, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization is completed.\n"
     ]
    }
   ],
   "source": [
    "tfidf_vector = TfidfVectorizer(min_df=3, analyzer='word', \n",
    "                               strip_accents='unicode', \n",
    "                               token_pattern=r'\\w{1}',\n",
    "                               ngram_range=(1,3), \n",
    "                               max_features=5000,\n",
    "                               use_idf=1, \n",
    "                               smooth_idf=1,\n",
    "                                sublinear_tf=1,\n",
    "                              stop_words='english')\n",
    "# TFIDFVectorizer \n",
    "X_train_vec, X_valid_vec = vectorize(tfidf_vector, X_train.flatten(), X_valid.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, bagging_seed=11,\n",
       "               boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, eval_metric='logloss',\n",
       "               feature_fraction=0.8, importance_type='split', lambda_l1=0.5,\n",
       "               learning_rate=0.2, max_depth=6, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_leaf=60, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=60,\n",
       "               objective='multiclass', random_state=42, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_params = {\n",
    "    'n_estimators': 500,\n",
    "    'num_leaves': 60,\n",
    "     'min_data_in_leaf': 60, \n",
    "     'objective':'multiclass',\n",
    "     'max_depth': 6,\n",
    "     'learning_rate': 0.2,\n",
    "     \"boosting\": \"gbdt\",\n",
    "     \"feature_fraction\": 0.8,\n",
    "     \"bagging_freq\": 1,\n",
    "     \"bagging_fraction\": 0.8 ,\n",
    "     \"bagging_seed\": 11,\n",
    "     \"eval_metric\": 'logloss',\n",
    "     \"lambda_l1\": 0.5,\n",
    "     \"random_state\": 42,\n",
    "    'verbose':1\n",
    "    \n",
    "}\n",
    "\n",
    "lgbm_clf = LGBMClassifier(**lgbm_params)\n",
    "lgbm_clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LinearSVC()\n",
    "model = LogisticRegression(C=1.0, \n",
    "                           class_weight='balanced')\n",
    "\n",
    "# Initialize OVR classifier with ML Algorithm\n",
    "ovr = OneVsRestClassifier(estimator=model)\n",
    "\n",
    "ovr.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.644 \tPrecision: 0.644 \tRecall: 0.644 \tF1-Score: 0.644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# y_pred = lgbm_clf.predict(X_valid_vec)\n",
    "y_pred = ovr.predict(X_valid_vec)\n",
    "\n",
    "print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\tF1-Score: %1.3f\\n\" % (accuracy_score(y_valid, y_pred),\n",
    "                                                                                     precision_score(y_valid, y_pred, average='micro'),\n",
    "                                                                                     recall_score(y_valid, y_pred, average='micro'),\n",
    "                                                                                     f1_score(y_valid, y_pred, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Text'] = test_data['TITLE'] + test_data['ABSTRACT']\n",
    "\n",
    "test_data['Processed'] = test_data['Text'].apply(DataPreprocess())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization is completed.\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "X_train_vec, X_test_vec = vectorize(tfidf_vector, X_train.flatten(), test_data['Processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds = lgbm_clf.predict(X_test_vec)\n",
    "y_preds = ovr.predict(X_test_vec)\n",
    "test_df = test_data.copy()\n",
    "\n",
    "test_df['category'] = pd.Series(y_preds, index=test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 0, 1, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[labels] = pd.get_dummies(test_df['category'], columns=labels)\n",
    "\n",
    "final_df = test_df.drop(['TITLE', 'ABSTRACT', 'Text', 'Processed', 'category'], axis=1)\n",
    "\n",
    "submission_data = final_df[submission_data.columns]\n",
    "\n",
    "submission_data\n",
    "\n",
    "submission_data.to_csv('multiclass_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
